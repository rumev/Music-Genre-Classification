{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from keras import layers\n",
    "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
    "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.backends.backend_tkagg import (FigureCanvasTkAgg, NavigationToolbar2Tk)\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "import tkinter as tk\n",
    "from PIL import ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_melspectrogram(wav_file):  \n",
    "  y,sr = librosa.load(wav_file)  \n",
    "  mels = librosa.feature.melspectrogram(y=y,sr=sr)    \n",
    "  fig = plt.Figure()  \n",
    "  canvas = FigureCanvas(fig) \n",
    "  p = plt.imshow(librosa.power_to_db(mels,ref=np.max))   \n",
    "  plt.savefig('melspectrogram.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_data,model):   \n",
    "  image = tf.keras.utils.img_to_array(image_data)   \n",
    "  image = np.reshape(image,(1,288,432,4))   \n",
    "  prediction =  model.predict(image/255)  \n",
    "  prediction = prediction.reshape((10,))     \n",
    "  class_label = np.argmax(prediction)     \n",
    "  return class_label,prediction\n",
    "class_labels = ['blues', 'classic ', 'country', 'disco', 'hiphop','jazz', 'metal', 'pop', 'reggae', 'rock'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio():\n",
    "    import sounddevice as sd\n",
    "    from scipy.io.wavfile import write\n",
    "    import wavio as wv\n",
    "  \n",
    "    \n",
    "    # Sampling frequency\n",
    "    freq = 44100\n",
    "  \n",
    "    # Recording duration\n",
    "    duration = 3\n",
    "  \n",
    "    # Start recorder with the given values \n",
    "    # of duration and sample frequency\n",
    "    recording = sd.rec(int(duration * freq), \n",
    "                   samplerate=freq, channels=2)\n",
    "  \n",
    "    # Record audio for the given number of seconds\n",
    "    sd.wait()\n",
    "  \n",
    "    # This will convert the NumPy array to an audio\n",
    "    # file with the given sampling frequency\n",
    "    write(\"recording0.wav\", freq, recording)\n",
    "  \n",
    "    # Convert the NumPy array to audio file\n",
    "    wv.write(\"recording1.wav\", recording, freq, sampwidth=2)\n",
    "    create_melspectrogram(\"recording1.wav\")\n",
    "    image_data = tf.keras.utils.load_img('melspectrogram.png',color_mode='rgba',target_size=(288,432))\n",
    "    class_label,prediction = predict(image_data,model)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0.1,0.1,0.89,0.8])\n",
    "    ax.bar(class_labels,prediction)\n",
    "    fig.savefig('prediction.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(imagefile):\n",
    "    image = ImageTk.PhotoImage(file=imagefile)\n",
    "    imagebox.config(image=image)\n",
    "    imagebox.image = image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model('C:\\FinalProject\\model.h5',compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "window = Tk()\n",
    "window.title(\"Music Genre Classification\")\n",
    "window.geometry(\"500x400\")\n",
    "app =Frame(window)\n",
    "app.pack()\n",
    "button1 = Button(app, text = \" Record Audio \" , width=20, command=record_audio)\n",
    "button1.pack(side=tk.LEFT)\n",
    "\n",
    "button2 = Button(app, text = \" Show Prediction \" , width=20, command=lambda: show_image(\"prediction.png\"))\n",
    "button2.pack(side=tk.LEFT)\n",
    "\n",
    "\n",
    "    \n",
    "imagebox = tk.Label(window)\n",
    "imagebox.pack()\n",
    " \n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
